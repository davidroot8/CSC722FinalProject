{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9e80355bf97747f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T01:19:50.841513Z",
     "start_time": "2024-04-18T01:19:50.838577Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import lightning as L\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "337f11f02251e3b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T01:24:19.038427Z",
     "start_time": "2024-04-18T01:24:19.033414Z"
    }
   },
   "outputs": [],
   "source": [
    "class CIFAR10Module(L.LightningDataModule):\n",
    "    def __init__(self, data_dir, batch_size=4, img_size=(32, 32), num_workers=4):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = img_size\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "        self.train_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Resize(self.img_size),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.2154, 0.2024))\n",
    "        ])\n",
    "        \n",
    "        self.val_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Resize(self.img_size),\n",
    "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.2154, 0.2024))\n",
    "        ])\n",
    "\n",
    "    def prepare_data(self):\n",
    "        datasets.CIFAR10(root=self.data_dir, train=True, download=True)\n",
    "        datasets.CIFAR10(root=self.data_dir, train=False, download=True)\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        train_dataset = datasets.CIFAR10(root=self.data_dir, train=True, transform=self.train_transform)\n",
    "        val_dataset = datasets.CIFAR10(root=self.data_dir, train=False, transform=self.val_transform)\n",
    "        self.train_set = train_dataset\n",
    "        self.val_set = val_dataset\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_set, batch_size=self.batch_size, shuffle=True, num_workers=self.num_workers, persistent_workers=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_set, batch_size=self.batch_size, num_workers=self.num_workers, persistent_workers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e81bc56543236e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T01:43:00.984767Z",
     "start_time": "2024-04-18T01:43:00.979237Z"
    }
   },
   "outputs": [],
   "source": [
    "class ResnetModel(L.LightningModule):\n",
    "    def __init__(self, num_classes=10, initial_lr=0.001, weight_decay=5e-4, gamma=0.1, step_size=5):\n",
    "        super().__init__()\n",
    "        self.model = torchvision.models.resnet18(weights='DEFAULT')\n",
    "        self.loss_module = nn.CrossEntropyLoss()\n",
    "        in_features = self.model.fc.in_features\n",
    "        self.model.fc = nn.Linear(in_features, num_classes)\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "        self.initial_lr = initial_lr\n",
    "        self.weight_decay = weight_decay\n",
    "        self.gamma = gamma\n",
    "        self.step_size = step_size\n",
    "\n",
    "    def forward(self, images):\n",
    "        return self.model(images)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        images, targets = batch\n",
    "        outputs = self.forward(images)\n",
    "\n",
    "        loss = F.cross_entropy(outputs, targets)\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        images, targets = batch\n",
    "        outputs = self.forward(images)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = F.cross_entropy(outputs, targets)\n",
    "        self.log('val_loss', loss, on_step=False, on_epoch=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.initial_lr, weight_decay=self.weight_decay)\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=self.step_size, gamma=self.gamma)\n",
    "        return [optimizer], [scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f60841d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /home/davidroot/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
      "100%|██████████| 44.7M/44.7M [00:00<00:00, 56.3MB/s]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | model       | ResNet           | 11.2 M\n",
      "1 | loss_module | CrossEntropyLoss | 0     \n",
      "-------------------------------------------------\n",
      "11.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.2 M    Total params\n",
      "44.727    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 1563/1563 [00:16<00:00, 93.72it/s, v_num=2]      \n"
     ]
    }
   ],
   "source": [
    "data_dir = 'data/'\n",
    "data_module = CIFAR10Module(data_dir, batch_size=32)\n",
    "model = ResnetModel(num_classes=10)\n",
    "\n",
    "logger = TensorBoardLogger(\"lightning_logs\", name=\"cifar10-resnet\")\n",
    "trainer = L.Trainer(\n",
    "    accelerator=\"auto\",\n",
    "    max_epochs=50,\n",
    "    callbacks=[\n",
    "        EarlyStopping(monitor=\"val_loss\", patience=1),\n",
    "        ModelCheckpoint(monitor=\"val_loss\", save_top_k=1)\n",
    "    ],\n",
    "    logger=logger\n",
    ")\n",
    "\n",
    "trainer.fit(model, data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64f9064",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
